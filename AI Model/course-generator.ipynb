{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import logging\n",
    "from urllib.parse import urljoin, urlparse, quote\n",
    "from typing import List, Dict, Any, Optional\n",
    "import os\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"course_generator.log\", encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('CourseGenerator')\n",
    "\n",
    "class ContentEnhancer:\n",
    "    \"\"\"Enhanced content generator with GPT-2 fallback\"\"\"\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            # Initialize GPT-2 model\n",
    "            self.model_name = \"gpt2-large\"\n",
    "            self.tokenizer = GPT2Tokenizer.from_pretrained(self.model_name)\n",
    "            self.model = GPT2LMHeadModel.from_pretrained(self.model_name)\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.model.to(self.device)\n",
    "            self.has_gpt = True\n",
    "            logger.info(\"GPT-2 model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            self.has_gpt = False\n",
    "            logger.warning(f\"Failed to load GPT-2 model: {str(e)}. Using simple enhancement only.\")\n",
    "\n",
    "    def enhance(self, text: str, context: str = \"\", max_length: int = 200) -> str:\n",
    "        \"\"\"Enhance text with GPT-2 if available, otherwise use simple enhancement\"\"\"\n",
    "        if not text and not context:\n",
    "            return \"\"\n",
    "\n",
    "        # If we have GPT-2 and the text is worth enhancing\n",
    "        if self.has_gpt and (len(text) > 50 or context):\n",
    "            try:\n",
    "                prompt = f\"Explain this {context}:\\n\\n{text[:500]}\\n\\nEnhanced explanation:\"\n",
    "\n",
    "                inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n",
    "                outputs = self.model.generate(\n",
    "                    inputs,\n",
    "                    max_length=max_length,\n",
    "                    num_return_sequences=1,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True\n",
    "                )\n",
    "\n",
    "                enhanced = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                # Extract just the enhanced part\n",
    "                if \"Enhanced explanation:\" in enhanced:\n",
    "                    enhanced = enhanced.split(\"Enhanced explanation:\")[-1]\n",
    "                return self._clean_text(enhanced)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"GPT-2 enhancement failed: {str(e)}\")\n",
    "                # Fall through to simple enhancement\n",
    "\n",
    "        # Simple enhancement fallback\n",
    "        return self._simple_enhance(text)\n",
    "\n",
    "    def generate_content(self, topic: str, level: str = \"beginner\", module_type: str = \"introduction\") -> str:\n",
    "        \"\"\"Generate content from scratch using GPT-2\"\"\"\n",
    "        if not self.has_gpt:\n",
    "            return f\"This would be a {level} level {module_type} about {topic}.\"\n",
    "\n",
    "        try:\n",
    "            prompt = f\"Create a {level} level {module_type} about {topic} with 2-3 key points:\"\n",
    "\n",
    "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n",
    "            outputs = self.model.generate(\n",
    "                inputs,\n",
    "                max_length=300,\n",
    "                num_return_sequences=1,\n",
    "                temperature=0.7,\n",
    "                do_sample=True\n",
    "            )\n",
    "\n",
    "            generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            return self._clean_text(generated)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Content generation failed: {str(e)}\")\n",
    "            return f\"Generated {level} level content about {topic}.\"\n",
    "\n",
    "    def _simple_enhance(self, text: str) -> str:\n",
    "        \"\"\"Basic text cleaning and formatting\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        # Capitalize first letter\n",
    "        if text:\n",
    "            text = text[0].upper() + text[1:]\n",
    "        return text\n",
    "\n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean generated text\"\"\"\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        # Remove any incomplete sentences at the end\n",
    "        text = re.sub(r'[^.!?]+$', '', text)\n",
    "        return text\n",
    "\n",
    "class CourseScraper:\n",
    "    \"\"\"Enhanced web scraper with difficulty detection\"\"\"\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "        }\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update(self.headers)\n",
    "\n",
    "        # Trusted educational sites\n",
    "        self.trusted_sites = [\n",
    "            'geeksforgeeks.org', 'w3schools.com', 'developer.mozilla.org',\n",
    "            'freecodecamp.org', 'digitalocean.com', 'realpython.com',\n",
    "            'tutorialspoint.com', 'javatpoint.com', 'learn.microsoft.com',\n",
    "            'docs.python.org'\n",
    "        ]\n",
    "\n",
    "        # Content extraction patterns\n",
    "        self.content_patterns = [\n",
    "            {'tag': 'article', 'attrs': {}},\n",
    "            {'tag': 'div', 'attrs': {'class': 'content'}},\n",
    "            {'tag': 'main', 'attrs': {}},\n",
    "            {'tag': 'div', 'attrs': {'id': 'content'}},\n",
    "            {'tag': 'div', 'attrs': {'class': 'article-body'}},\n",
    "            {'tag': 'div', 'attrs': {'class': 'entry-content'}},\n",
    "            {'tag': 'div', 'attrs': {'class': 'post-content'}},\n",
    "            {'tag': 'div', 'attrs': {'class': 'tutorial-content'}}\n",
    "        ]\n",
    "\n",
    "        # Code extraction patterns\n",
    "        self.code_patterns = [\n",
    "            {'tag': 'pre', 'attrs': {}},\n",
    "            {'tag': 'code', 'attrs': {}},\n",
    "            {'tag': 'div', 'attrs': {'class': 'highlight'}}\n",
    "        ]\n",
    "\n",
    "        # URLs to avoid\n",
    "        self.avoid_patterns = [\n",
    "            'practice', 'quiz', 'exercise', 'test',\n",
    "            'forum', 'signup', 'login', 'profile',\n",
    "            'course', 'certificate', 'pricing'\n",
    "        ]\n",
    "\n",
    "        self.visited = set()\n",
    "        self.max_pages = 5\n",
    "        self.delay = (1, 3)\n",
    "\n",
    "    def search_topic(self, topic: str) -> List[str]:\n",
    "        \"\"\"Find relevant educational content for a topic\"\"\"\n",
    "        topic = self._clean_query(topic)\n",
    "        if not topic:\n",
    "            return []\n",
    "\n",
    "        # Try direct URLs first\n",
    "        urls = []\n",
    "        for site in self.trusted_sites:\n",
    "            # The method _generate_direct_urls was called, but it was not defined.\n",
    "            # Changed to call _generate_and_check_urls instead.\n",
    "            urls.extend(self._generate_and_check_urls(site, topic))\n",
    "            if len(urls) >= self.max_pages:\n",
    "                break\n",
    "            time.sleep(random.uniform(*self.delay))\n",
    "\n",
    "        # If we didn't get enough URLs, try Google search\n",
    "        if len(urls) < self.max_pages:\n",
    "            google_urls = self._google_search(topic)\n",
    "            urls.extend(google_urls)\n",
    "\n",
    "        return list(dict.fromkeys(urls))[:self.max_pages]\n",
    "    def _generate_and_check_urls(self, site: str, topic: str) -> List[str]:\n",
    "      \"\"\"Generate direct URLs for a site based on common patterns and check which ones exist\"\"\"\n",
    "      topic_slug = topic.replace(' ', '-').lower()\n",
    "      topic_underscore = topic.replace(' ', '_').lower()\n",
    "\n",
    "      generated_urls = []\n",
    "      valid_urls = []\n",
    "\n",
    "      if site == 'w3schools.com':\n",
    "          generated_urls = [\n",
    "              f\"https://www.w3schools.com/{topic_slug}/default.asp\",\n",
    "              f\"https://www.w3schools.com/{topic_slug}_intro.asp\",\n",
    "              f\"https://www.w3schools.com/tags/{topic_slug}.asp\",\n",
    "              f\"https://www.w3schools.com/{topic_slug}/index.php\"\n",
    "          ]\n",
    "      elif site == 'geeksforgeeks.org':\n",
    "          generated_urls = [\n",
    "              f\"https://www.geeksforgeeks.org/{topic_slug}-tutorial/\",\n",
    "              f\"https://www.geeksforgeeks.org/introduction-to-{topic_slug}/\",\n",
    "              f\"https://www.geeksforgeeks.org/{topic_slug}-basics/\"\n",
    "          ]\n",
    "      elif site == 'developer.mozilla.org':\n",
    "          generated_urls = [\n",
    "              f\"https://developer.mozilla.org/en-US/docs/Web/{topic_slug}\",\n",
    "              f\"https://developer.mozilla.org/en-US/docs/Learn/{topic_slug}\"\n",
    "          ]\n",
    "      elif site == 'tutorialspoint.com':\n",
    "          generated_urls = [\n",
    "              f\"https://www.tutorialspoint.com/{topic_slug}/index.htm\",\n",
    "              f\"https://www.tutorialspoint.com/{topic_underscore}_tutorial.htm\"\n",
    "          ]\n",
    "      elif site == 'realpython.com':\n",
    "          generated_urls = [\n",
    "              f\"https://realpython.com/{topic_slug}/\",\n",
    "              f\"https://realpython.com/{topic_slug}-tutorial/\"\n",
    "          ]\n",
    "      elif site == 'javatpoint.com':\n",
    "          generated_urls = [\n",
    "              f\"https://www.javatpoint.com/{topic_slug}-tutorial\",\n",
    "              f\"https://www.javatpoint.com/{topic_slug}\"\n",
    "          ]\n",
    "      else:\n",
    "          # Generic patterns for other sites\n",
    "          generated_urls = [\n",
    "              f\"https://www.{site}/{topic_slug}\",\n",
    "              f\"https://www.{site}/{topic_slug}-tutorial\",\n",
    "              f\"https://www.{site}/tutorial/{topic_slug}\",\n",
    "              f\"https://www.{site}/docs/{topic_slug}\"\n",
    "          ]\n",
    "\n",
    "      # Check each URL to see if it exists\n",
    "      for url in generated_urls:\n",
    "          try:\n",
    "              response = requests.head(url, allow_redirects=True, timeout=5)\n",
    "              if response.status_code == 200:\n",
    "                  valid_urls.append(url)\n",
    "          except requests.RequestException:\n",
    "              continue\n",
    "\n",
    "      return valid_urls\n",
    "\n",
    "    def _google_search(self, query: str) -> List[str]:\n",
    "        \"\"\"Fallback to extract URLs from Google search\"\"\"\n",
    "        try:\n",
    "            # Format a Google search URL with site: operators for our trusted sites\n",
    "            site_filters = \" OR \".join([f\"site:{site}\" for site in self.trusted_sites])\n",
    "            search_url = f\"https://www.google.com/search?q={quote(query)}+{quote(site_filters)}\"\n",
    "\n",
    "            # Add a referrer to avoid being blocked\n",
    "            special_headers = self.headers.copy()\n",
    "            special_headers['Referer'] = 'https://www.google.com/'\n",
    "\n",
    "            # Make the request\n",
    "            response = requests.get(search_url, headers=special_headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Parse the response\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Extract URLs - Google puts them in <a> tags with href attributes\n",
    "            # that start with \"/url?q=\"\n",
    "            urls = []\n",
    "            for a in soup.find_all('a', href=True):\n",
    "                href = a['href']\n",
    "                if href.startswith('/url?q='):\n",
    "                    # Extract actual URL\n",
    "                    url = href.split('/url?q=')[1].split('&')[0]\n",
    "                    # Check if it's from a trusted site\n",
    "                    if any(site in url for site in self.trusted_sites):\n",
    "                        urls.append(url)\n",
    "\n",
    "            return urls\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Google search failed: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def scrape_page(self, url: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Scrape content from a single page with difficulty detection\"\"\"\n",
    "        if any(bad in url.lower() for bad in self.avoid_patterns):\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            response = self.session.get(url, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Extract content\n",
    "            title = self._clean_text(soup.title.string if soup.title else \"Untitled\")\n",
    "            content = self._extract_content(soup)\n",
    "            code_examples = self._extract_code(soup)\n",
    "\n",
    "            # Determine difficulty level\n",
    "            difficulty = self._determine_difficulty(content, url)\n",
    "\n",
    "            return {\n",
    "                'title': title,\n",
    "                'content': content,\n",
    "                'code_examples': code_examples,\n",
    "                'url': url,\n",
    "                'difficulty': difficulty\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to scrape {url}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _determine_difficulty(self, content: str, url: str) -> str:\n",
    "        \"\"\"Determine difficulty level of content\"\"\"\n",
    "        text = (content + \" \" + url).lower()\n",
    "\n",
    "        # Advanced indicators\n",
    "        advanced_terms = ['advanced', 'expert', 'deep dive', 'optimization',\n",
    "                         'algorithm', 'complexity', 'performance', 'concurrency',\n",
    "                         'asynchronous', 'multithreading', 'design pattern']\n",
    "        if any(term in text for term in advanced_terms):\n",
    "            return \"advanced\"\n",
    "\n",
    "        # Intermediate indicators\n",
    "        intermediate_terms = ['intermediate', 'guide', 'tutorial', 'how to',\n",
    "                             'implementation', 'function', 'method', 'class',\n",
    "                             'object', 'api', 'library']\n",
    "        if any(term in text for term in intermediate_terms):\n",
    "            return \"intermediate\"\n",
    "\n",
    "        # Default to beginner\n",
    "        return \"beginner\"\n",
    "\n",
    "    def _extract_content(self, soup: BeautifulSoup) -> str:\n",
    "        \"\"\"Extract main content from page\"\"\"\n",
    "        # Try each content pattern\n",
    "        for pattern in self.content_patterns:\n",
    "            elements = soup.find_all(pattern['tag'], pattern['attrs'] if pattern['attrs'] else {})\n",
    "            if elements:\n",
    "                # Take the longest content block (likely the main content)\n",
    "                text = max([self._clean_text(el.get_text()) for el in elements], key=len, default=\"\")\n",
    "                if len(text) > 100:  # Ensure we have substantial content\n",
    "                    return text\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "    def _extract_code(self, soup: BeautifulSoup) -> List[str]:\n",
    "        \"\"\"Extract code examples from page\"\"\"\n",
    "        examples = []\n",
    "        for pattern in self.code_patterns:\n",
    "            for element in soup.find_all(pattern['tag'], pattern['attrs'] if pattern['attrs'] else {}):\n",
    "                code = self._clean_code(element.get_text())\n",
    "                if code and len(code) > 10:  # Ensure it's not just a tiny code snippet\n",
    "                    examples.append(code)\n",
    "        return examples\n",
    "\n",
    "    def _clean_query(self, text: str) -> str:\n",
    "        \"\"\"Clean search query\"\"\"\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text).strip().lower()\n",
    "\n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean extracted text content\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'Advertisement\\s*', '', text, flags=re.IGNORECASE)\n",
    "        return text.strip()\n",
    "\n",
    "    def _clean_code(self, code: str) -> str:\n",
    "        \"\"\"Clean code examples\"\"\"\n",
    "        if not code:\n",
    "            return \"\"\n",
    "        return re.sub(r'\\s+\\n', '\\n', code).strip()\n",
    "\n",
    "class CourseGenerator:\n",
    "    \"\"\"Enhanced course generator with difficulty levels and GPT fallback\"\"\"\n",
    "    def __init__(self):\n",
    "        self.scraper = CourseScraper()\n",
    "        self.enhancer = ContentEnhancer()\n",
    "\n",
    "    def generate_course(self, topic: str, target_level: str = \"all\") -> dict:\n",
    "        \"\"\"Generate a course with optional difficulty filtering\"\"\"\n",
    "        logger.info(f\"Generating {target_level} course for: {topic}\")\n",
    "\n",
    "        # Find and scrape relevant pages\n",
    "        urls = self.scraper.search_topic(topic)\n",
    "        if not urls:\n",
    "            return self._generate_fallback_course(topic)\n",
    "\n",
    "        pages = []\n",
    "        for url in urls:\n",
    "            content = self.scraper.scrape_page(url)\n",
    "            if content:\n",
    "                pages.append(content)\n",
    "            time.sleep(random.uniform(*self.scraper.delay))\n",
    "\n",
    "        if not pages:\n",
    "            return self._generate_fallback_course(topic)\n",
    "\n",
    "        # Filter by difficulty if requested\n",
    "        if target_level.lower() != \"all\":\n",
    "            pages = [p for p in pages if p['difficulty'].lower() == target_level.lower()]\n",
    "            if not pages:\n",
    "                return {\n",
    "                    \"error\": f\"No {target_level} content found for '{topic}'\",\n",
    "                    \"suggestion\": \"Try generating a course for all levels\"\n",
    "                }\n",
    "\n",
    "        # Structure the course\n",
    "        course_level = self._determine_course_level(pages)\n",
    "        modules = self._create_modules(pages, topic, course_level)\n",
    "\n",
    "        # Ensure we have at least 3 modules\n",
    "        if len(modules) < 3:\n",
    "            modules = self._fill_missing_modules(modules, topic, course_level)\n",
    "\n",
    "        return {\n",
    "            \"title\": f\"{topic.title()} Course\",\n",
    "            \"level\": course_level,\n",
    "            \"modules\": modules,\n",
    "            \"resources\": [p['url'] for p in pages if 'url' in p],\n",
    "            \"generated_date\": time.strftime(\"%Y-%m-%d\")\n",
    "        }\n",
    "\n",
    "    def _generate_fallback_course(self, topic: str) -> dict:\n",
    "        \"\"\"Generate a course using GPT when scraping fails\"\"\"\n",
    "        logger.warning(f\"Generating fallback course for: {topic}\")\n",
    "\n",
    "        # Create basic modules with GPT-generated content\n",
    "        modules = []\n",
    "        module_types = [\"introduction\", \"core concepts\", \"advanced topics\"]\n",
    "\n",
    "        for i, module_type in enumerate(module_types):\n",
    "            content = self.enhancer.generate_content(topic, \"beginner\", module_type)\n",
    "            modules.append({\n",
    "                \"title\": f\"Module {i+1}: {module_type.title()}\",\n",
    "                \"content\": content,\n",
    "                \"examples\": [],\n",
    "                \"difficulty\": \"beginner\",\n",
    "                \"generated\": True  # Mark as GPT-generated\n",
    "            })\n",
    "\n",
    "        return {\n",
    "            \"title\": f\"{topic.title()} Course (Generated)\",\n",
    "            \"level\": \"beginner\",\n",
    "            \"modules\": modules,\n",
    "            \"resources\": [],\n",
    "            \"generated_date\": time.strftime(\"%Y-%m-%d\"),\n",
    "            \"warning\": \"This course was generated automatically as no relevant content was found\"\n",
    "        }\n",
    "\n",
    "    def _fill_missing_modules(self, existing_modules: List[dict], topic: str, level: str) -> List[dict]:\n",
    "        \"\"\"Fill in missing modules with GPT-generated content\"\"\"\n",
    "        target_count = 3  # We want at least 3 modules\n",
    "        if len(existing_modules) >= target_count:\n",
    "            return existing_modules\n",
    "\n",
    "        # Determine what types of modules we need\n",
    "        module_types = [\"introduction\", \"core concepts\", \"advanced topics\"]\n",
    "        existing_types = [m['title'].lower() for m in existing_modules]\n",
    "\n",
    "        new_modules = existing_modules.copy()\n",
    "\n",
    "        for i in range(target_count - len(existing_modules)):\n",
    "            # Find a module type we don't have yet\n",
    "            for module_type in module_types:\n",
    "                if module_type not in existing_types:\n",
    "                    content = self.enhancer.generate_content(topic, level, module_type)\n",
    "                    new_modules.append({\n",
    "                        \"title\": f\"Module {len(new_modules)+1}: {module_type.title()}\",\n",
    "                        \"content\": content,\n",
    "                        \"examples\": [],\n",
    "                        \"difficulty\": level,\n",
    "                        \"generated\": True\n",
    "                    })\n",
    "                    existing_types.append(module_type)\n",
    "                    break\n",
    "\n",
    "        return new_modules\n",
    "\n",
    "    def _determine_course_level(self, pages: List[dict]) -> str:\n",
    "        \"\"\"Determine overall course level based on module levels\"\"\"\n",
    "        levels = [p['difficulty'] for p in pages]\n",
    "        if \"advanced\" in levels:\n",
    "            return \"advanced\"\n",
    "        if \"intermediate\" in levels:\n",
    "            return \"intermediate\"\n",
    "        return \"beginner\"\n",
    "\n",
    "    def _create_modules(self, pages: List[dict], topic: str, course_level: str) -> List[dict]:\n",
    "        \"\"\"Organize content into modules with enhanced explanations\"\"\"\n",
    "        modules = []\n",
    "\n",
    "        # Sort pages by difficulty (beginners first)\n",
    "        pages.sort(key=lambda p: [\"beginner\", \"intermediate\", \"advanced\"].index(p['difficulty']))\n",
    "\n",
    "        for i, page in enumerate(pages):\n",
    "            # Enhance content with context\n",
    "            enhanced_content = self.enhancer.enhance(\n",
    "                page['content'],\n",
    "                f\"{topic} {page['title']} at {page['difficulty']} level\"\n",
    "            )\n",
    "\n",
    "            module = {\n",
    "                \"title\": f\"Module {i+1}: {page['title']}\",\n",
    "                \"content\": enhanced_content,\n",
    "                \"examples\": [],\n",
    "                \"difficulty\": page['difficulty'],\n",
    "                \"source\": page['url']\n",
    "            }\n",
    "\n",
    "            # Add code examples with explanations\n",
    "            for j, code in enumerate(page['code_examples'][:2]):\n",
    "                module[\"examples\"].append({\n",
    "                    \"title\": f\"Example {j+1} from {page['title']}\",\n",
    "                    \"code\": code,\n",
    "                    \"explanation\": self.enhancer.enhance(\n",
    "                        \"\",\n",
    "                        f\"explanation of this {topic} code example: {code[:100]}...\"\n",
    "                    )\n",
    "                })\n",
    "\n",
    "            modules.append(module)\n",
    "\n",
    "        return modules\n",
    "\n",
    "    def interactive_mode(self):\n",
    "        \"\"\"Enhanced interactive interface with difficulty selection\"\"\"\n",
    "        print(\"\\n=== Enhanced Course Generator ===\")\n",
    "        while True:\n",
    "            topic = input(\"\\nEnter a programming topic (or 'quit'): \").strip()\n",
    "            if topic.lower() == 'quit':\n",
    "                break\n",
    "\n",
    "            if not topic:\n",
    "                print(\"Please enter a valid topic\")\n",
    "                continue\n",
    "\n",
    "            print(\"\\nSelect difficulty level:\")\n",
    "            print(\"1. Beginner\")\n",
    "            print(\"2. Intermediate\")\n",
    "            print(\"3. Advanced\")\n",
    "            print(\"4. All Levels\")\n",
    "            level_choice = input(\"Enter choice (1-4): \").strip()\n",
    "\n",
    "            levels = {\n",
    "                \"1\": \"beginner\",\n",
    "                \"2\": \"intermediate\",\n",
    "                \"3\": \"advanced\",\n",
    "                \"4\": \"all\"\n",
    "            }\n",
    "            target_level = levels.get(level_choice, \"all\")\n",
    "\n",
    "            course = self.generate_course(topic, target_level)\n",
    "            self._display_course(course)\n",
    "\n",
    "    def _display_course(self, course: dict):\n",
    "        \"\"\"Display course information and handle saving\"\"\"\n",
    "        if \"error\" in course:\n",
    "            print(f\"\\nError: {course['error']}\")\n",
    "            if \"suggestion\" in course:\n",
    "                print(f\"Suggestion: {course['suggestion']}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nGenerated Course: {course['title']}\")\n",
    "        print(f\"Level: {course['level'].title()}\")\n",
    "        print(f\"Modules: {len(course['modules'])}\")\n",
    "        print(f\"Date: {course['generated_date']}\")\n",
    "\n",
    "        if \"warning\" in course:\n",
    "            print(f\"\\nWarning: {course['warning']}\")\n",
    "\n",
    "        # Show module previews\n",
    "        for i, module in enumerate(course['modules']):\n",
    "            print(f\"\\nModule {i+1}: {module['title']}\")\n",
    "            print(f\"Difficulty: {module['difficulty'].title()}\")\n",
    "            if module.get('generated'):\n",
    "                print(\"[AI-Generated Content]\")\n",
    "            preview = module['content'][:100] + \"...\" if len(module['content']) > 100 else module['content']\n",
    "            print(f\"Preview: {preview}\")\n",
    "            print(f\"Examples: {len(module['examples'])}\")\n",
    "\n",
    "        # Show resources if available\n",
    "        if course['resources']:\n",
    "            print(\"\\nResources:\")\n",
    "            for url in course['resources']:\n",
    "                print(f\"- {url}\")\n",
    "\n",
    "        # Save option\n",
    "        save = input(\"\\nSave to file? (y/n): \").lower()\n",
    "        if save == 'y':\n",
    "            self._save_course(course)\n",
    "\n",
    "    def _save_course(self, course: dict):\n",
    "        \"\"\"Save course to markdown file\"\"\"\n",
    "        filename = f\"{course['title'].replace(' ', '_').lower()}_course.md\"\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"# {course['title']}\\n\\n\")\n",
    "                f.write(f\"**Level:** {course['level'].title()}\\n\")\n",
    "                f.write(f\"**Generated:** {course['generated_date']}\\n\\n\")\n",
    "\n",
    "                if \"warning\" in course:\n",
    "                    f.write(f\"> Note: {course['warning']}\\n\\n\")\n",
    "\n",
    "                f.write(\"## Course Overview\\n\\n\")\n",
    "                f.write(f\"This course covers {course['title'].split(' Course')[0]} at {course['level']} level.\\n\\n\")\n",
    "\n",
    "                for module in course['modules']:\n",
    "                    f.write(f\"## {module['title']}\\n\\n\")\n",
    "                    if module.get('generated'):\n",
    "                        f.write(\"> This content was generated automatically\\n\\n\")\n",
    "                    f.write(f\"**Difficulty:** {module['difficulty'].title()}\\n\\n\")\n",
    "                    f.write(f\"{module['content']}\\n\\n\")\n",
    "\n",
    "                    if module['examples']:\n",
    "                        f.write(\"### Code Examples\\n\\n\")\n",
    "                        for example in module['examples']:\n",
    "                            f.write(f\"#### {example['title']}\\n\\n\")\n",
    "                            f.write(f\"```\\n{example['code']}\\n```\\n\\n\")\n",
    "                            f.write(f\"{example['explanation']}\\n\\n\")\n",
    "\n",
    "                if course['resources']:\n",
    "                    f.write(\"## Resources\\n\\n\")\n",
    "                    for url in course['resources']:\n",
    "                        f.write(f\"- [{urlparse(url).netloc}]({url})\\n\")\n",
    "\n",
    "            print(f\"Course saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save course: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generator = CourseGenerator()\n",
    "    generator.interactive_mode()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
